% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/main_functions.R
\name{seqm}
\alias{seqm}
\title{Fitting sequence models}
\usage{
seqm(seqs, response, response_type, actions, rnn_type = "lstm", K = 20,
  n_hidden = 0, K_hidden = NULL, valid_split = 0, index_valid = NULL,
  max_len = max(sapply(seqs, length)), n_epoch = 20, batch_size = 16,
  optimizer_name = "rmsprop", step_size = 0.001, gpu = TRUE)
}
\arguments{
\item{seqs}{a list of \code{n} action sequences. Each element is an action
sequence in the form of a vector of actions.}

\item{response}{the binary response variable.}

\item{response_type}{"binary" or "scale".}

\item{actions}{a character vector gives all possible actions. It is will be
expanded to include all actions appear in \code{seqs} if necessary.}

\item{rnn_type}{the type of recurrent unit to be used for modeling
action sequences. \code{"lstm"} for the long-short term memory unit. 
\code{"gru"} for the gated recurrent unit.}

\item{K}{the latent dimension of the embedding layer and the recurrent layer.}

\item{n_hidden}{the number of hidden fully-connected layers.}

\item{K_hidden}{a vector of length \code{n_hidden} specifying the number of
nodes in each hidden layer.}

\item{valid_split}{proportion of sequences used as the validation set.}

\item{index_valid}{a vector of indices specifying the validation set.}

\item{max_len}{the maximum length of input sequences.}

\item{n_epoch}{the number of training epochs.}

\item{batch_size}{the batch size used in training.}

\item{optimizer_name}{a character string specifying the optimizer to be used
for training. Availabel options are \code{"sgd"}, \code{"rmsprop"}, 
\code{"adadelta"}, and \code{"adam"}.}

\item{step_size}{the learning rate of optimizer.}

\item{gpu}{logical. If TRUE, use gpu for training if available.}
}
\value{
\code{seqm} returns an object of class \code{"seqm"}, which is a list containing 
  \item{model}{a vector of class \code{"raw"}. It is the serialized version of 
    the trained keras model.} 
  \item{actions}{all possible actions.}
  \item{max_len}{the maximum length of action sequences.}
  \item{history}{a \code{n_epoch} by 2 matrix giving the training and
  validation losses at the end of each epoch.}
}
\description{
\code{seqm} is used to fit a neural network model relating action sequences
with a response variable.
}
\details{
The model consists of an embedding layer, a recurrent layer and one or more
fully connected layers. The embedding layer takes a action sequence and
output a sequences of \code{K} dimensional numeric vectors to the recurrent
layer. The last output of the recurrent layer is used as the input of the
subsequent fully connected layers. If \code{response_type="binary"}, the last
layer uses the sigmoid activation to produce the probability of the response
being positive. If \code{response_type="scale"}, the last layer uses the linear
activation. The dimension of the output of other fully connected layers
(if any) is specified by \code{K_hidden}.

The action sequences are re-coded into integer sequences and are padded with
zeros to length \code{max_len} before feeding into the model. If the provided
\code{max_len} is smaller than the length of the longest sequence in
\code{seqs}, it will be overridden.
}
\examples{
n <- 100
seqs <- seq_gen(n)
y1 <- sapply(seqs, function(x) "CHECK_A" \%in\% x)
y2 <- sapply(seqs, function(x) log10(length(x)))

index_test <- 91:100
index_train <- 1:90

actions <- unique(unlist(seqs))

res1 <- seqm(seqs[index_train], y1[index_train], "binary", actions=actions, valid_split=0.2)
predict(res1, new_seqs = seqs[index_test])

res1_more <- seqm(seqs[index_train], y1[index_train], "binary", actions=actions, valid_split=0.2, K=20, n_hidden=2, K_hidden=c(10,5))
predict(res1_more, new_seqs = seqs[index_test])

res2 <- seqm(seqs[index_train], y2[index_train], "scale", actions=actions, valid_split=0.2)
predict(res2, new_seqs = seqs[index_test])

}
\seealso{
\code{\link{predict.seqm}} for the \code{predict} method for \code{seqm} objects.
}
